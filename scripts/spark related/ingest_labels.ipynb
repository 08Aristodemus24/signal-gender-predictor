{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee1a92e0-fe2a-44d6-9a12-fe3f8524c819",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import pyspark\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "from pyspark.sql import SparkSession, Window\n",
    "from pyspark.conf import SparkConf\n",
    "# from pyspark.context import SparkContext\n",
    "from pyspark.sql.types import StringType, ArrayType, StructField, StructType, FloatType, DoubleType, IntegerType\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "80ba5ea9-0e29-49bd-b917-33e6050b70fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# `sparksession is none: typeerror: 'javapackage' object is not \n",
    "# callable` can be raised if the pyspark version being used is 4.0.0\n",
    "# which is not compatible to a python 3.11.8 version\n",
    "\n",
    "# if we have 24 gb of installed ram and 23 gb usable and have\n",
    "# 8 cores in our CPU we can utilize this memory to partition \n",
    "# it across all 8 cores of our cpu for concurrent processing \n",
    "# in spark. We need to also take note of background processes \n",
    "# in our task manager taking up our memory so if need be we \n",
    "# have to end these background processes that take up too much \n",
    "# memory in order to free up space for our spark driver memory \n",
    "# and spark executor memory\n",
    "\n",
    "# lets say we have 8 cores per node/CPU and currently 23gb usable ram\n",
    "# we can partition this 23gb ram across all 8 cores of the CPU\n",
    "# since there are other background processes we can reserve 1 core\n",
    "# for this as well as 1gb of ram, and so we will have only 7 cores \n",
    "# available and 22gb of ram\n",
    "\n",
    "# executors utilize cores the ff. are different kinds of executor\n",
    "# sizes\n",
    "# executor 1: [<core 1>, <core 2>, ..., <core 7>] where 22gb of ram is\n",
    "# spread out across the executors. Since there is only a single executor \n",
    "# here executor will only have 22gb of memory and then this memory will \n",
    "# be divided into its individual cores which currently have 7 so 22 / 7 \n",
    "# is 3gb of memory per core\n",
    "\n",
    "# the main idea is we can have any number of executors so long as there\n",
    "# are any number of cores but we cannot have any number of cores for\n",
    "# any number of executors. If there are 7 cores we can have at most\n",
    "# 7 executors and divide the ram across these executors and their cores\n",
    "# themselves. \n",
    "\n",
    "# executor 1: [<core 1>]\n",
    "# executor 2: [<core 2>]\n",
    "# executor 3: [<core 3>]\n",
    "# executor 4: [<core 4>]\n",
    "# executor 5: [<core 5>]\n",
    "# executor 6: [<core 6>]\n",
    "# executor 1: [<core 7>]\n",
    "# where the 22fb of ram we have is spread out across these executors\n",
    "# if we have 7 executors we will have 22 / 7 or 3gb. Therefore 3gb will\n",
    "# be the memory of each executor with one actually 4gb as 3gb + 3gb + \n",
    "# 3gb + 3gb + 3gb + 3gb + 4gb = 22gb. And \n",
    "\n",
    "# again our starting memory and cores is 24gb and 8 cores\n",
    "# we will minus 1gb and 1core for yarn/hadoop processes\n",
    "# making it 23gb and 7 cores. Yarn application master\n",
    "# can take either 1gb of ram or 1 core therefore it may make\n",
    "# our total memory and cores 22gb and 7 cores or 23gb and 6 cores;\n",
    "# say we picked the former. Now we choose our number of executors\n",
    "# which can be the mid range of our number of cores. Say we want\n",
    "# 3 executors then each executor will have 22gb / 3 or 7gb, 7gb, \n",
    "# 8gb respectively for all 3 executors.\n",
    "# executor 1 (7gb): []\n",
    "# executor 2 (7gb): []\n",
    "# executor 3 (8gb): []\n",
    "# we also take into consideration memory overhead for each\n",
    "# executor which is `memory per executor` - `max(384mb, 10 % of spark.executor.memory)`\n",
    "# after calculation our executor memories will now have the ff.\n",
    "# 7000mb - max(384mb, 10% of 7gb is 0.7gb or 700mb) = 6300mb or 6.3gb\n",
    "# 7000mb - max(384mb, 10% of 7gb is 0.7gb or 700mb) = 6300mb or 6.3gb\n",
    "# 8000mb - max(384mb, 10% of 8gb is 0.8gb or 800mb) = 7200mb or 7.2gb\n",
    "# executor 1 (6.3gb): []\n",
    "# executor 2 (6.3gb): []\n",
    "# executor 3 (7.2gb): []\n",
    "# since we havee 7 cores we can divide these cores across all these\n",
    "# executors. if distributed evenly each executor will have 2, 2, and 3\n",
    "# cores respectively\n",
    "\n",
    "\n",
    "# driver memory default is 1g\n",
    "# executor memory default is 1g\n",
    "# executor cores default is 1\n",
    "# sql execution arrow maxRecordsPerBatch default 10000 \n",
    "# maximum number of records that can be written to a single ArrowRecordBatch in memory\n",
    "\n",
    "# spark = SparkSession.builder.appName(\"app\")\\\n",
    "    # .config(\"spark.driver.memory\", \"16g\")\\\n",
    "    # .config(\"spark.executor.memory\", \"4g\")\\\n",
    "    # .config(\"spark.executor.cores\", \"2\")\\\n",
    "    # .config(\"spark.executor.instances\", \"3\")\\\n",
    "    # .config(\"spark.sql.execution.arrow.maxRecordsPerBatch\", \"100\")\\\n",
    "    # .getOrCreate()\n",
    "\n",
    "spark = SparkSession.builder.appName(\"app\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6643cd3c-e0b7-4146-a488-84d84b20d87a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{DATA_DIR}/{FOLDER_NAME}'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # cloud\n",
    "# BRONZE_FOLDER_NAME = \"sgppipelinesa-bronze\"\n",
    "# URL = \"abfss://{FOLDER_NAME}@sgppipelinesa.dfs.core.windows.net\"\n",
    "# BRONZE_DATA_DIR = os.path.join(URL, \"\").replace(\"\\\\\", \"/\")\n",
    "# BRONZE_DATA_DIR\n",
    "\n",
    "# local\n",
    "BRONZE_FOLDER_NAME = \"bronze\"\n",
    "DATA_DIR = \"../../include/data\"\n",
    "BRONZE_DATA_DIR = os.path.join(\"{DATA_DIR}\", \"{FOLDER_NAME}\").replace(\"\\\\\", \"/\")\n",
    "BRONZE_DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "608751f0-344b-467b-9672-45433aa9ecc0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# sample_folder = folder_infos[-1].path\n",
    "# sample_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b8829f80-e22c-4a4a-9aa1-1381ab00f8d0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# sample_folder.strip('/').split('/')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e982f28-f272-4576-91d9-b07ec18c3ffa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# type(folder_infos[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a1e55de7-a37a-4e39-8889-bf57f0092284",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# dbutils.fs.ls(folder_infos[-1].path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4afdf976-964e-4946-99e8-f2d21bea1f18",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # cloud\n",
    "# file_infos = [file_info.path for file_info in dbutils.fs.ls(BRONZE_DATA_PATH)]\n",
    "# file_infos\n",
    "\n",
    "# local\n",
    "file_infos = [\n",
    "    os.path.join(BRONZE_DATA_DIR.format(DATA_DIR=DATA_DIR, FOLDER_NAME=BRONZE_FOLDER_NAME), file_info).replace(\"\\\\\", \"/\") \n",
    "    for file_info in \n",
    "    os.listdir(BRONZE_DATA_DIR.format(DATA_DIR=DATA_DIR, FOLDER_NAME=BRONZE_FOLDER_NAME))\n",
    "]\n",
    "file_infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f978569b-1c1f-4d9e-a385-5c1bd68873e6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# labels_df = spark.read.format('text')\\\n",
    "#     .option(\"lineSep\", \"\\n\")\\\n",
    "#     .load(os.path.join(BRONZE_DATA_PATH, \"1337ad-20170321-ajg\", \"etc\", \"README\"))\n",
    "# labels_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_paths = [\n",
    "    os.path.join(file_info, \"etc\", \"README\").replace(\"\\\\\", \"/\") \n",
    "    for file_info in file_infos \n",
    "    if os.path.exists(os.path.join(file_info, \"etc\", \"README\").replace(\"\\\\\", \"/\"))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c51a6e32-2db6-400d-850a-b27df0c056f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# cloud\n",
    "labels_df = spark.read.format(\"text\")\\\n",
    "    .option(\"lineSep\", \"\\n\")\\\n",
    "    .load(label_paths)\\\n",
    "    .select(\"*\", \"_metadata.file_path\")\n",
    "\n",
    "# local\n",
    "# labels_df = spark.read.format(\"text\")\\\n",
    "#     .option(\"lineSep\", \"\\n\")\\\n",
    "#     .load([os.path.join(BRONZE_DATA_PATH, file_info, \"etc\", \"README\") for file_info in file_infos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[value: string, file_path: string]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+\n",
      "|value|file_path|\n",
      "+-----+---------+\n",
      "+-----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "15f914d7-b5fc-4c80-a7c4-f56e2bd695ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# labels_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fa05cc71-89c4-48cb-aa30-ea21fa972c68",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# labels_df.withColumn(\"filePath\", F.input_file_name()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee5e370f-9202-4f52-bfda-5ff0c7095ef9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# labels_df.withColumn(\"filePath\", F.input_file_name()).where(\n",
    "#     F.lower(F.col(\"value\")).contains(\"gender\")\n",
    "# ).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e081e2e-0baf-43ce-866b-836041459fd5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# local\n",
    "# labels_df = labels_df.withColumn(\"filePath\", F.input_file_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e99b5258-9209-4372-874f-f09b041d2fde",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+---------+-----+---------+\n",
      "|value|file_path|subjectId|rowId|partition|\n",
      "+-----+---------+---------+-----+---------+\n",
      "+-----+---------+---------+-----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels_df = labels_df.where(F.lower(F.col(\"value\")).contains(\"gender\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "73b2d0b2-5317-4939-821d-d44409fe212d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Clean value columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0fb51cba-11fa-4752-8317-9b63289d9bfc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "labels_df = labels_df.withColumn(\n",
    "    \"value\", \n",
    "    # extract only the gender of the subject in meta data\n",
    "    F.regexp_replace(\n",
    "        F.lower(F.col(\"value\")), \n",
    "        r\"(gender)|[:;\\[\\]\\t\\n\\s]+\", \n",
    "        \"\"\n",
    "    )\n",
    ")\n",
    "# labels_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af0c8558-f26b-4253-925c-ab32ed12d711",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "labels_df = labels_df.withColumn(\n",
    "    \"value\",\n",
    "    # sometimes the gender may be in a different language\n",
    "    # e.g. the 'male' in german may have the string start\n",
    "    # with 'mä' so we should return male if this is the case\n",
    "    # and vice versa for females translated to a different\n",
    "    # language \n",
    "    F.when(\n",
    "        F.col(\"value\").startswith(\"ma\") | F.col(\"value\").startswith(\"mä\"),\n",
    "        \"male\"\n",
    "    ).when(\n",
    "        F.col(\"value\").startswith(\"fem\") | F.col(\"value\").startswith(\"wei\"),\n",
    "        \"female\"\n",
    "    ).otherwise(\n",
    "        \"unknown\"\n",
    "    )\n",
    ")\n",
    "# labels_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6be5f784-1060-4094-a26c-29e3dacbaf69",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# clean filePath column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a403dfe-2347-4b42-9c1d-8972d1674725",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# labels_df.withColumn(\n",
    "#     \"subjectId\",\n",
    "#     F.element_at(\n",
    "#         # splits the filepath from 'file:///c:/Users/LARRY/Documents/Scripts/.../bronze/1337ad-20170321-ajg/etc/README\n",
    "#         # to array of the directory tree of the files path e.g. \n",
    "#         # ['file:', ..., 'Scripts', ..., 'bronze', '<subject id>, 'etc', 'readme']\n",
    "#         # so in order to extract subject id or the file name we have to \n",
    "#         # get the 3rd to the last element\n",
    "#         F.split(\n",
    "#             F.col(\"file_path\"),\n",
    "#             r\"\\/\"\n",
    "#         ),\n",
    "#         -3\n",
    "#     )\n",
    "# ).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "854164e5-7d7b-4d39-8f7f-ddeb81f1ec61",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "labels_df = labels_df.withColumn(\n",
    "    \"subjectId\",\n",
    "    F.element_at(\n",
    "        # splits the filepath from 'file:///c:/Users/LARRY/Documents/Scripts/.../bronze/1337ad-20170321-ajg/etc/README\n",
    "        # to array of the directory tree of the files path e.g. \n",
    "        # ['file:', ..., 'Scripts', ..., 'bronze', '<subject id>, 'etc', 'readme']\n",
    "        # so in order to extract subject id or the file name we have to \n",
    "        # get the 3rd to the last element\n",
    "        F.split(\n",
    "            F.col(\"file_path\"),\n",
    "            r\"\\/\"\n",
    "        ),\n",
    "        -3\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[value: string, file_path: string, subjectId: string, rowId: int, partition: int]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+---------+-----+---------+\n",
      "|value|file_path|subjectId|rowId|partition|\n",
      "+-----+---------+---------+-----+---------+\n",
      "+-----+---------+---------+-----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[value: string, file_path: string, subjectId: string]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "male_labels_df = labels_df.where(F.col(\"value\") == \"male\")\n",
    "male_labels_df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[value: string, file_path: string, subjectId: string]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "female_labels_df = labels_df.where(F.col(\"value\") == \"female\")\n",
    "female_labels_df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_male_labels_df, val_male_labels_df, test_male_labels_df = male_labels_df.randomSplit(weights=[0.7, 0.15, 0.15], seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_female_labels_df, val_female_labels_df, test_female_labels_df = female_labels_df.randomSplit(weights=[0.7, 0.15, 0.15], seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[value: string, file_path: string, subjectId: string]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_male_labels_df.cache()\n",
    "val_male_labels_df.cache()\n",
    "test_male_labels_df.cache()\n",
    "train_female_labels_df.cache()\n",
    "val_female_labels_df.cache()\n",
    "test_female_labels_df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[value: string, file_path: string, subjectId: string]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels_df = train_male_labels_df.unionByName(train_female_labels_df)\n",
    "train_labels_df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[value: string, file_path: string, subjectId: string]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_labels_df = val_male_labels_df.unionByName(val_female_labels_df)\n",
    "val_labels_df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[value: string, file_path: string, subjectId: string]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels_df = test_male_labels_df.unionByName(test_female_labels_df)\n",
    "test_labels_df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[value: string, file_path: string, subjectId: string, rowId: int]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create an ID column so that when this is saved\n",
    "# randomly we can order the dataframe again in the \n",
    "# next second stage transformation\n",
    "id_window = Window.orderBy(F.col(\"subjectId\"))\n",
    "train_labels_df = train_labels_df.withColumn(\"rowId\", F.row_number().over(id_window) - 1)\n",
    "val_labels_df = val_labels_df.withColumn(\"rowId\", F.row_number().over(id_window) - 1)\n",
    "test_labels_df = test_labels_df.withColumn(\"rowId\", F.row_number().over(id_window) - 1)\n",
    "train_labels_df.cache()\n",
    "val_labels_df.cache()\n",
    "test_labels_df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[value: string, file_path: string, subjectId: string, rowId: int, partition: int]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_partitions = 10\n",
    "train_labels_df = train_labels_df.withColumn(\"partition\", F.col(\"rowId\") % n_partitions)\n",
    "val_labels_df = val_labels_df.withColumn(\"partition\", F.col(\"rowId\") % n_partitions)\n",
    "test_labels_df = test_labels_df.withColumn(\"partition\", F.col(\"rowId\") % n_partitions)\n",
    "train_labels_df.cache()\n",
    "val_labels_df.cache()\n",
    "test_labels_df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------------------+-----+---------+\n",
      "| value|           file_path|           subjectId|rowId|partition|\n",
      "+------+--------------------+--------------------+-----+---------+\n",
      "|female|file:/c:/Users/LA...| 1337ad-20170321-ajg|    0|        0|\n",
      "|female|file:/c:/Users/LA...| 1337ad-20170321-tkg|    1|        1|\n",
      "|female|file:/c:/Users/LA...| 1337ad-20170321-ynk|    2|        2|\n",
      "|  male|file:/c:/Users/LA...|23yipikaye-201008...|    3|        3|\n",
      "|  male|file:/c:/Users/LA...|2old2play-2011060...|    4|        4|\n",
      "|  male|file:/c:/Users/LA...|2old2play-2011060...|    5|        5|\n",
      "|  male|file:/c:/Users/LA...|314piwm-20130617-xuo|    6|        6|\n",
      "|  male|file:/c:/Users/LA...|     AT-20130718-lws|    7|        7|\n",
      "|  male|file:/c:/Users/LA...|  Aaron-20080318-kdl|    8|        8|\n",
      "|  male|file:/c:/Users/LA...|  Aaron-20080318-lbb|    9|        9|\n",
      "|  male|file:/c:/Users/LA...|  Aaron-20080318-lbk|   10|        0|\n",
      "|  male|file:/c:/Users/LA...|  Aaron-20080318-liy|   11|        1|\n",
      "|  male|file:/c:/Users/LA...|  Aaron-20080318-ngh|   12|        2|\n",
      "|  male|file:/c:/Users/LA...|  Aaron-20080318-pwn|   13|        3|\n",
      "|  male|file:/c:/Users/LA...|AbdulMoiz-2012101...|   14|        4|\n",
      "|  male|file:/c:/Users/LA...|   Adminvox-05232006|   15|        5|\n",
      "|  male|file:/c:/Users/LA...|   Adminvox-05262006|   16|        6|\n",
      "|  male|file:/c:/Users/LA...|AdrianMcNear-2009...|   17|        7|\n",
      "|  male|file:/c:/Users/LA...|  Afzal-20110524-qsu|   18|        8|\n",
      "|  male|file:/c:/Users/LA...|Airwings-20101216...|   19|        9|\n",
      "+------+--------------------+--------------------+-----+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_labels_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e31a0eaa-f47f-4633-8132-9b8dce911bbc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../include/data/silver\\\\stage-01'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # cloud\n",
    "# SILVER_FOLDER_NAME = \"sgppipelinesa-silver\"\n",
    "# SUB_FOLDER_NAME = \"stage-01\"\n",
    "# SILVER_DATA_DIR = os.path.join(URL.format(FOLDER_NAME=SILVER_FOLDER_NAME), SUB_FOLDER_NAME)\n",
    "# SILVER_DATA_DIR\n",
    "\n",
    "# local\n",
    "SILVER_FOLDER_NAME = \"silver\"\n",
    "SUB_FOLDER_NAME = \"stage-01\"\n",
    "SILVER_DATA_DIR = os.path.join(DATA_DIR, os.path.join(SILVER_FOLDER_NAME, SUB_FOLDER_NAME))\n",
    "SILVER_DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "46f24c9c-8fb8-4a32-8992-9206c58cafdb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_labels_df.write\\\n",
    ".option(\"compression\", \"snappy\")\\\n",
    ".mode(\"overwrite\")\\\n",
    ".partitionBy(\"partition\")\\\n",
    ".parquet(os.path.join(SILVER_DATA_DIR, \"train\", \"labels.parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_labels_df.write\\\n",
    ".option(\"compression\", \"snappy\")\\\n",
    ".mode(\"overwrite\")\\\n",
    ".partitionBy(\"partition\")\\\n",
    ".parquet(os.path.join(SILVER_DATA_DIR, \"val\", \"labels.parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels_df.write\\\n",
    ".option(\"compression\", \"snappy\")\\\n",
    ".mode(\"overwrite\")\\\n",
    ".partitionBy(\"partition\")\\\n",
    ".parquet(os.path.join(SILVER_DATA_DIR, \"test\", \"labels.parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[value: string, file_path: string, subjectId: string, rowId: int, partition: int]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels_df.unpersist()\n",
    "val_labels_df.unpersist()\n",
    "test_labels_df.unpersist()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "load_labels",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "tech-interview",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
