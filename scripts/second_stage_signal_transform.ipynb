{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8aa806d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrowfs_adlgen2 as pa_adl\n",
    "import pyarrow.dataset as ds\n",
    "import numpy as np\n",
    "import librosa\n",
    "import duckdb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "from azure.identity import DefaultAzureCredential, ClientSecretCredential\n",
    "from azure.storage.filedatalake import DataLakeServiceClient\n",
    "from azure.keyvault.secrets import SecretClient\n",
    "from azure.core.exceptions import ResourceNotFoundError\n",
    "\n",
    "from utilities.visualizers import view_signal_feature\n",
    "from utilities.feature_extractors import extract_spectogam_stats\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "01a55d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../include/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9d404efc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{FOLDER_NAME}/{SUB_FOLDER_NAME}'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cloud\n",
    "# URL = \"abfss://{FOLDER_NAME}@sgppipelinesa.dfs.core.windows.net\"\n",
    "URL = \"{FOLDER_NAME}\"\n",
    "SILVER_FOLDER_NAME = \"sgppipelinesa-silver\"\n",
    "SUB_FOLDER_NAME = \"stage-01\"\n",
    "SILVER_DATA_DIR = os.path.join(URL, \"{SUB_FOLDER_NAME}\").replace(\"\\\\\", \"/\")\n",
    "SILVER_DATA_DIR\n",
    "\n",
    "# # local\n",
    "# SILVER_FOLDER_NAME = \"silver\"\n",
    "# SUB_FOLDER_NAME = \"stage-01\"\n",
    "# SILVER_DATA_DIR = os.path.join(\"{DATA_DIR}\", \"{FOLDER_NAME}\", \"{SUB_FOLDER_NAME}\").replace(\"\\\\\", \"/\")\n",
    "# SILVER_DATA_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9a781d",
   "metadata": {},
   "source": [
    "# Computing features for a single subjects audio signals\n",
    "this is to familiarize what exact features we need to compute for all other subjects audio signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "caa42962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # anonymous-20080904-qzg_signals\n",
    "# # _caustic_-20170306-smy_signals\n",
    "# subject_table = pq.read_table(\n",
    "#     os.path.join(\n",
    "#         SILVER_DATA_DIR.format(\n",
    "#             DATA_DIR=DATA_DIR,\n",
    "#             FOLDER_NAME=SILVER_FOLDER_NAME,\n",
    "#             SUB_FOLDER_NAME=SUB_FOLDER_NAME\n",
    "#         ), \n",
    "#         \"anonymous-20080904-qzg_signals.parquet\"\n",
    "#     )\n",
    "# )\n",
    "# subject_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "07b06df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # connect to an in-memory database\n",
    "# conn = duckdb.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "337f6739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conn.sql(\"\"\"\n",
    "#     SELECT COUNT(*) FROM subject_table\n",
    "# \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "30e9494f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # hertz\n",
    "# hertz = 16000\n",
    "# window_time = 3\n",
    "# hop_time = 1\n",
    "\n",
    "# # we calculate the window size of each segment or the\n",
    "# # amount of samples it has to have based on the frequency\n",
    "# samples_per_win_size = int(window_time * hertz)\n",
    "# samples_per_hop_size = int(hop_time * hertz)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5504e78",
   "metadata": {},
   "source": [
    "# Computing statistical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e6c1f5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conn.sql(f\"\"\"\n",
    "#     CREATE OR REPLACE TEMPORARY TABLE subject_features AS (\n",
    "#         SELECT\n",
    "#             signals, \n",
    "#             subjectId, \n",
    "#             rowId,\n",
    "#             KURTOSIS(signals) OVER(PARTITION BY subjectId ORDER BY rowId ROWS BETWEEN CURRENT ROW AND {samples_per_win_size - 1} FOLLOWING) AS freq_kurt,\n",
    "#             SKEWNESS(signals) OVER(PARTITION BY subjectId ORDER BY rowId ROWS BETWEEN CURRENT ROW AND {samples_per_win_size - 1} FOLLOWING) AS freq_skew,\n",
    "#             ENTROPY(signals)OVER(PARTITION BY subjectId ORDER BY rowId ROWS BETWEEN CURRENT ROW AND {samples_per_win_size - 1} FOLLOWING) AS freq_entropy,\n",
    "#             AVG(signals) OVER(PARTITION BY subjectId ORDER BY rowId ROWS BETWEEN CURRENT ROW AND {samples_per_win_size - 1} FOLLOWING) AS freq_mean,\n",
    "#             MEDIAN(signals) OVER(PARTITION BY subjectId ORDER BY rowId ROWS BETWEEN CURRENT ROW AND {samples_per_win_size - 1} FOLLOWING) AS freq_median,\n",
    "#             MODE(signals) OVER(PARTITION BY subjectId ORDER BY rowId ROWS BETWEEN CURRENT ROW AND {samples_per_win_size - 1} FOLLOWING) AS freq_mode,\n",
    "#             MIN(signals) OVER(PARTITION BY subjectId ORDER BY rowId ROWS BETWEEN CURRENT ROW AND {samples_per_win_size - 1} FOLLOWING) AS freq_min,\n",
    "#             MAX(signals) OVER(PARTITION BY subjectId ORDER BY rowId ROWS BETWEEN CURRENT ROW AND {samples_per_win_size - 1} FOLLOWING) AS freq_max,\n",
    "#             VAR_SAMP(signals) OVER(PARTITION BY subjectId ORDER BY rowId ROWS BETWEEN CURRENT ROW AND {samples_per_win_size - 1} FOLLOWING) AS freq_var,\n",
    "#             STDDEV_SAMP(signals) OVER(PARTITION BY subjectId ORDER BY rowId ROWS BETWEEN CURRENT ROW AND {samples_per_win_size - 1} FOLLOWING) AS freq_stddev,\n",
    "#             QUANTILE_CONT(signals, 0.25) OVER(PARTITION BY subjectId ORDER BY rowId ROWS BETWEEN CURRENT ROW AND {samples_per_win_size - 1} FOLLOWING) AS freq_first_quart,\n",
    "#             QUANTILE_CONT(signals, 0.75) OVER(PARTITION BY subjectId ORDER BY rowId ROWS BETWEEN CURRENT ROW AND {samples_per_win_size - 1} FOLLOWING) AS freq_third_quart\n",
    "#         FROM subject_table\n",
    "#         WHERE (rowId % {samples_per_hop_size}) = 0\n",
    "#         ORDER BY rowId\n",
    "#     )\n",
    "# \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8ab48ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conn.sql(\"\"\"\n",
    "#     CREATE OR REPLACE TEMPORARY TABLE subject_features AS (\n",
    "#         SELECT \n",
    "#             *,\n",
    "#             (freq_max - freq_min) AS freq_range,\n",
    "#             (freq_third_quart - freq_first_quart) AS freq_inter_quart_range\n",
    "#         FROM subject_features\n",
    "#     )\n",
    "# \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "14bd3595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conn.sql(\"\"\"\n",
    "#     SELECT * FROM subject_features\n",
    "# \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b271669",
   "metadata": {},
   "source": [
    "#### 544000 + a window of 48000 is 592000 which is greater 553472 so we consider only the indeces 544000 to 553471 which is just 9471 rows of data for this last window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "462203c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conn.sql(\"\"\"\n",
    "#     SELECT COUNT(*) FROM subject_table\n",
    "# \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736bf5c1",
   "metadata": {},
   "source": [
    "# imputing missing or null values created from feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f6c34ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conn.sql(\"\"\"\n",
    "#     SELECT \n",
    "#         COALESCE(\n",
    "#             freq_kurt, \n",
    "#             (SELECT AVG(freq_kurt) FROM subject_features)\n",
    "#         ) AS freq_kurt_imp,\n",
    "#         COALESCE(\n",
    "#             freq_skew, \n",
    "#             (SELECT AVG(freq_skew) FROM subject_features)\n",
    "#         ) AS freq_skew_imp,\n",
    "#         COALESCE(\n",
    "#             freq_entropy, \n",
    "#             (SELECT AVG(freq_entropy) FROM subject_features)\n",
    "#         ) AS freq_entropy_imp\n",
    "#     FROM subject_features\n",
    "# \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae884b35",
   "metadata": {},
   "source": [
    "# Computing spectral features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "093f1130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# frames = conn.sql(\"\"\"\n",
    "#     SELECT COUNT(rowId) FROM subject_features\n",
    "# \"\"\").fetchall()[-1][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b7833f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "57669863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time = librosa.frames_to_time(frames, sr=hertz, hop_length=samples_per_hop_size)\n",
    "# time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d5ca0198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subject_table[\"signals\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e2b2dc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_signals = subject_table[\"signals\"].to_numpy()\n",
    "# x_signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "15e40015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # calculate other features\n",
    "# zcr = librosa.feature.zero_crossing_rate(y=x_signals, frame_length=samples_per_win_size, hop_length=samples_per_hop_size)\n",
    "# zcr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "18187fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zcr.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a78de9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_zcr = zcr.reshape(-1)\n",
    "# new_zcr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1837fc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view_signal_feature(new_zcr, \"zero crossing rate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba1798b",
   "metadata": {},
   "source": [
    "#### sometimes the calculation of spectral features may lead to 1 or more data points being added when compared to the length of the number of statistical features computed based on window length and hop length. To make sure number of values of statistical features and spectral features are the same we get only the first n rows of this spectral features based solely on the number of rows of the statistical features e.g. if there are 35 successfully calculated statistical features and we have 36 calculated spectral features we only get the first 35 of the spectral features and discard the rest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "602fadd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zcr_n_values_to_rem = np.abs(zcr.shape[1] - time)\n",
    "# zcr_n_values_to_rem.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0fdb4f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get slice of those in range with time only\n",
    "# new_zcr = zcr.reshape(-1)[:frames]\n",
    "# new_zcr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4f74de38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_zcr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b1a6a9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # these are 2 features all in all we don't need to aggregate it\n",
    "# # into a (1, 35) array\n",
    "# poly_feats = librosa.feature.poly_features(y=x_signals, sr=hertz, n_fft=samples_per_win_size, hop_length=samples_per_hop_size)\n",
    "# poly_feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "84e8b138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_poly_feats = poly_feats[:, :frames]\n",
    "# new_poly_feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "47d1cb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # y is the audio signals we must pass\n",
    "# # sr is the sampling rate of our audio signals\n",
    "# # n_fft is the window size of the fast fourier transform\n",
    "# # hop_length is number of samples between successive frames\n",
    "# # n_mels is the number of Mel bands to generate\n",
    "# mel_spec = librosa.feature.melspectrogram(y=x_signals, sr=hertz, n_fft=samples_per_win_size, hop_length=samples_per_hop_size, n_mels=90)\n",
    "# mel_spec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "507b5b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mel_spec_mean, \\\n",
    "# mel_spec_median, \\\n",
    "# mel_spec_mode, \\\n",
    "# mel_spec_mode_cnt, \\\n",
    "# mel_spec_min, \\\n",
    "# mel_spec_max, \\\n",
    "# mel_spec_range, \\\n",
    "# mel_spec_var, \\\n",
    "# mel_spec_std, \\\n",
    "# mel_spec_first_quart, \\\n",
    "# mel_spec_third_quart, \\\n",
    "# mel_spec_inter_quart_range, \\\n",
    "# mel_spec_entropy, \\\n",
    "# mel_spec_kurt, \\\n",
    "# mel_spec_skew = extract_spectogam_stats(mel_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "31cf64a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mel_spec_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8661e4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mel_spec_mean.shape, mel_spec_median.shape, mel_spec_mode.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "03600ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mel_spec_entropy.shape, mel_spec_kurt.shape, mel_spec_skew.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cfd665ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# librosa.display.specshow(mel_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "49029ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "# mel_spec_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2d066014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mel_spec_db_mean, \\\n",
    "# mel_spec_db_median, \\\n",
    "# mel_spec_db_mode, \\\n",
    "# mel_spec_db_mode_cnt, \\\n",
    "# mel_spec_db_min, \\\n",
    "# mel_spec_db_max, \\\n",
    "# mel_spec_db_range, \\\n",
    "# mel_spec_db_var, \\\n",
    "# mel_spec_db_std, \\\n",
    "# mel_spec_db_first_quart, \\\n",
    "# mel_spec_db_third_quart, \\\n",
    "# mel_spec_db_inter_quart_range, \\\n",
    "# mel_spec_db_entropy, \\\n",
    "# mel_spec_db_kurt, \\\n",
    "# mel_spec_db_skew = extract_spectogam_stats(mel_spec_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2259a4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# librosa.display.specshow(mel_spec_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "937b97a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spec_cent = librosa.feature.spectral_centroid(y=x_signals, sr=hertz, n_fft=samples_per_win_size, hop_length=samples_per_hop_size)\n",
    "# spec_cent.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ff903cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_spec_cent = spec_cent.reshape(-1)\n",
    "# new_spec_cent.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fc041ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view_signal_feature(new_spec_cent, \"spectral centroid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3176b8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mfcc = librosa.feature.mfcc(y=x_signals, sr=hertz, n_fft=samples_per_win_size, hop_length=samples_per_hop_size, n_mfcc=90)\n",
    "# mfcc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "33c34d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mfcc_mean, \\\n",
    "# mfcc_median, \\\n",
    "# mfcc_mode, \\\n",
    "# mfcc_mode_cnt, \\\n",
    "# mfcc_min, \\\n",
    "# mfcc_max, \\\n",
    "# mfcc_range, \\\n",
    "# mfcc_var, \\\n",
    "# mfcc_std, \\\n",
    "# mfcc_first_quart, \\\n",
    "# mfcc_third_quart, \\\n",
    "# mfcc_inter_quart_range, \\\n",
    "# mfcc_entropy, \\\n",
    "# mfcc_kurt, \\\n",
    "# mfcc_skew = extract_spectogam_stats(mfcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6dc22b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# librosa.display.specshow(mfcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "91b75fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spec_bw = librosa.feature.spectral_bandwidth(y=x_signals, sr=hertz, n_fft=samples_per_win_size, hop_length=samples_per_hop_size)\n",
    "# spec_bw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8887c28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_spec_bw = spec_bw.reshape(-1)\n",
    "# new_spec_bw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "cc698fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view_signal_feature(new_spec_bw, \"spectral bandwidth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0c3c52c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spec_cont = librosa.feature.spectral_contrast(y=x_signals, sr=hertz, n_fft=samples_per_win_size, hop_length=samples_per_hop_size)\n",
    "# spec_cont.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "056a092f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spec_cont_mean, \\\n",
    "# spec_cont_median, \\\n",
    "# spec_cont_mode, \\\n",
    "# spec_cont_mode_cnt, \\\n",
    "# spec_cont_min, \\\n",
    "# spec_cont_max, \\\n",
    "# spec_cont_range, \\\n",
    "# spec_cont_var, \\\n",
    "# spec_cont_std, \\\n",
    "# spec_cont_first_quart, \\\n",
    "# spec_cont_third_quart, \\\n",
    "# spec_cont_inter_quart_range, \\\n",
    "# spec_cont_entropy, \\\n",
    "# spec_cont_kurt, \\\n",
    "# spec_cont_skew = extract_spectogam_stats(spec_cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e2e6701a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# librosa.display.specshow(spec_cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e1c68836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spec_flat = librosa.feature.spectral_flatness(y=x_signals, n_fft=samples_per_win_size, hop_length=samples_per_hop_size)\n",
    "# spec_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b1468853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_spec_flat = spec_flat.reshape(-1)\n",
    "# new_spec_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ce5990f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view_signal_feature(new_spec_flat, \"spectral flatness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a5aac092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spec_roll = librosa.feature.spectral_rolloff(y=x_signals, sr=hertz, n_fft=samples_per_win_size, hop_length=samples_per_hop_size)\n",
    "# spec_roll.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2b9a4d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_spec_roll = spec_roll.reshape(-1)\n",
    "# new_spec_roll.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b231b007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view_signal_feature(new_spec_roll, \"spectral rolloff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5c639996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subject_features = conn.sql(\"\"\"\n",
    "#     SELECT * FROM subject_features\n",
    "# \"\"\").to_arrow_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c8a8184d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subject_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5d2caa70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subject_features = subject_features.append_column(\"zcr\", [new_zcr])\n",
    "# subject_features = subject_features.append_column(\"poly_feat_1\", [poly_feats[0, :]])\n",
    "# subject_features = subject_features.append_column(\"poly_feat_2\", [poly_feats[1, :]])\n",
    "# subject_features = subject_features.append_column(\"spec_cent\", [new_spec_cent])\n",
    "# subject_features = subject_features.append_column(\"spec_bw\", [new_spec_bw])\n",
    "# subject_features = subject_features.append_column(\"spec_flat\", [new_spec_flat])\n",
    "# subject_features = subject_features.append_column(\"spec_roll\", [new_spec_roll])\n",
    "\n",
    "# subject_features = subject_features.append_column(\"mel_spec_mean\", [mel_spec_mean])\n",
    "# subject_features = subject_features.append_column(\"mel_spec_median\", [mel_spec_median])\n",
    "# subject_features = subject_features.append_column(\"mel_spec_mode\", [mel_spec_mode])\n",
    "# subject_features = subject_features.append_column(\"mel_spec_mode_cnt\", [mel_spec_mode_cnt])\n",
    "# subject_features = subject_features.append_column(\"mel_spec_min\", [mel_spec_min])\n",
    "# subject_features = subject_features.append_column(\"mel_spec_max\", [mel_spec_max])\n",
    "# subject_features = subject_features.append_column(\"mel_spec_range\", [mel_spec_range])\n",
    "# subject_features = subject_features.append_column(\"mel_spec_var\", [mel_spec_var])\n",
    "# subject_features = subject_features.append_column(\"mel_spec_std\", [mel_spec_std])\n",
    "# subject_features = subject_features.append_column(\"mel_spec_first_quart\", [mel_spec_first_quart])\n",
    "# subject_features = subject_features.append_column(\"mel_spec_third_quart\", [mel_spec_third_quart])\n",
    "# subject_features = subject_features.append_column(\"mel_spec_inter_quart_range\", [mel_spec_inter_quart_range])\n",
    "# subject_features = subject_features.append_column(\"mel_spec_entropy\", [mel_spec_entropy])\n",
    "# subject_features = subject_features.append_column(\"mel_spec_kurt\", [mel_spec_kurt])\n",
    "# subject_features = subject_features.append_column(\"mel_spec_skew\", [mel_spec_skew])\n",
    "\n",
    "# subject_features = subject_features.append_column(\"mel_spec_db_mean\", [mel_spec_db_mean])\n",
    "# subject_features = subject_features.append_column(\"mel_spec_db_median\", [mel_spec_db_median])\n",
    "# subject_features = subject_features.append_column(\"mel_spec_db_mode\", [mel_spec_db_mode])\n",
    "# subject_features = subject_features.append_column(\"mel_spec_db_mode_cnt\", [mel_spec_db_mode_cnt])\n",
    "# subject_features = subject_features.append_column(\"mel_spec_db_min\", [mel_spec_db_min])\n",
    "# subject_features = subject_features.append_column(\"mel_spec_db_max\", [mel_spec_db_max])\n",
    "# subject_features = subject_features.append_column(\"mel_spec_db_range\", [mel_spec_db_range])\n",
    "# subject_features = subject_features.append_column(\"mel_spec_db_var\", [mel_spec_db_var])\n",
    "# subject_features = subject_features.append_column(\"mel_spec_db_std\", [mel_spec_db_std])\n",
    "# subject_features = subject_features.append_column(\"mel_spec_db_first_quart\", [mel_spec_db_first_quart])\n",
    "# subject_features = subject_features.append_column(\"mel_spec_db_third_quart\", [mel_spec_db_third_quart])\n",
    "# subject_features = subject_features.append_column(\"mel_spec_db_inter_quart_range\", [mel_spec_db_inter_quart_range])\n",
    "# subject_features = subject_features.append_column(\"mel_spec_db_entropy\", [mel_spec_db_entropy])\n",
    "# subject_features = subject_features.append_column(\"mel_spec_db_kurt\", [mel_spec_db_kurt])\n",
    "# subject_features = subject_features.append_column(\"mel_spec_db_skew\", [mel_spec_db_skew])\n",
    "\n",
    "# subject_features = subject_features.append_column(\"mfcc_mean\", [mfcc_mean])\n",
    "# subject_features = subject_features.append_column(\"mfcc_median\", [mfcc_median])\n",
    "# subject_features = subject_features.append_column(\"mfcc_mode\", [mfcc_mode])\n",
    "# subject_features = subject_features.append_column(\"mfcc_mode_cnt\", [mfcc_mode_cnt])\n",
    "# subject_features = subject_features.append_column(\"mfcc_min\", [mfcc_min])\n",
    "# subject_features = subject_features.append_column(\"mfcc_max\", [mfcc_max])\n",
    "# subject_features = subject_features.append_column(\"mfcc_range\", [mfcc_range])\n",
    "# subject_features = subject_features.append_column(\"mfcc_var\", [mfcc_var])\n",
    "# subject_features = subject_features.append_column(\"mfcc_std\", [mfcc_std])\n",
    "# subject_features = subject_features.append_column(\"mfcc_first_quart\", [mfcc_first_quart])\n",
    "# subject_features = subject_features.append_column(\"mfcc_third_quart\", [mfcc_third_quart])\n",
    "# subject_features = subject_features.append_column(\"mfcc_inter_quart_range\", [mfcc_inter_quart_range])\n",
    "# subject_features = subject_features.append_column(\"mfcc_entropy\", [mfcc_entropy])\n",
    "# subject_features = subject_features.append_column(\"mfcc_kurt\", [mfcc_kurt])\n",
    "# subject_features = subject_features.append_column(\"mfcc_skew\", [mfcc_skew])\n",
    "\n",
    "# subject_features = subject_features.append_column(\"spec_cont_mean\", [spec_cont_mean])\n",
    "# subject_features = subject_features.append_column(\"spec_cont_median\", [spec_cont_median])\n",
    "# subject_features = subject_features.append_column(\"spec_cont_mode\", [spec_cont_mode])\n",
    "# subject_features = subject_features.append_column(\"spec_cont_mode_cnt\", [spec_cont_mode_cnt])\n",
    "# subject_features = subject_features.append_column(\"spec_cont_min\", [spec_cont_min])\n",
    "# subject_features = subject_features.append_column(\"spec_cont_max\", [spec_cont_max])\n",
    "# subject_features = subject_features.append_column(\"spec_cont_range\", [spec_cont_range])\n",
    "# subject_features = subject_features.append_column(\"spec_cont_var\", [spec_cont_var])\n",
    "# subject_features = subject_features.append_column(\"spec_cont_std\", [spec_cont_std])\n",
    "# subject_features = subject_features.append_column(\"spec_cont_first_quart\", [spec_cont_first_quart])\n",
    "# subject_features = subject_features.append_column(\"spec_cont_third_quart\", [spec_cont_third_quart])\n",
    "# subject_features = subject_features.append_column(\"spec_cont_inter_quart_range\", [spec_cont_inter_quart_range])\n",
    "# subject_features = subject_features.append_column(\"spec_cont_entropy\", [spec_cont_entropy])\n",
    "# subject_features = subject_features.append_column(\"spec_cont_kurt\", [spec_cont_kurt])\n",
    "# subject_features = subject_features.append_column(\"spec_cont_skew\", [spec_cont_skew])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4e3cd676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subject_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "17a8930c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subject_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834e343c",
   "metadata": {},
   "source": [
    "# We have computed more than enough features we need, now we will load all of the subjects audio signal parquet files into one giant table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "07fbb939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # local\n",
    "# signal_file_paths = [\n",
    "#     os.path.join(\n",
    "#         SILVER_DATA_DIR.format(\n",
    "#             DATA_DIR=DATA_DIR,\n",
    "#             SILVER_FOLDER_NAME=SILVER_FOLDER_NAME,\n",
    "#             SUB_FOLDER_NAME=SUB_FOLDER_NAME\n",
    "#         ), \n",
    "#         signal_file_path\n",
    "#     ).replace(\"\\\\\", \"/\") \n",
    "#     for signal_file_path in os.listdir(SILVER_DATA_DIR.format(\n",
    "#         DATA_DIR=DATA_DIR,\n",
    "#         SILVER_FOLDER_NAME=SILVER_FOLDER_NAME,\n",
    "#         SUB_FOLDER_NAME=SUB_FOLDER_NAME\n",
    "#     )) \n",
    "#     if (not \"labels\" in signal_file_path) and (\".parquet\" in signal_file_path)\n",
    "# ]\n",
    "# len(signal_file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "841a8870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # local\n",
    "# signal_file_paths_test = [\n",
    "#     os.path.join(\n",
    "#         SILVER_DATA_DIR.format(\n",
    "#             DATA_DIR=DATA_DIR,\n",
    "#             SILVER_FOLDER_NAME=SILVER_FOLDER_NAME,\n",
    "#             SUB_FOLDER_NAME=SUB_FOLDER_NAME\n",
    "#         ),\n",
    "#         signal_file_path_test\n",
    "#     ).replace(\"\\\\\", \"/\")\n",
    "#     for signal_file_path_test in [\"anonymous-20080904-qzg_signals.parquet\", \"_caustic_-20170306-smy_signals.parquet\"]\n",
    "# ]\n",
    "# signal_file_paths_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "142e1017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve credentials from environment variables\n",
    "# this is strictly used only in development\n",
    "# load env variables\n",
    "env_dir = Path('../').resolve()\n",
    "load_dotenv(os.path.join(env_dir, '.env'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9a7a7d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_account_name = os.environ.get(\"STORAGE_ACCOUNT_NAME\")\n",
    "credential = os.environ.get(\"STORAGE_ACCOUNT_KEY\")\n",
    "conn_str = os.environ.get(\"STORAGE_ACCOUNT_CONN_STR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d94183b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{FOLDER_NAME}/{SUB_FOLDER_NAME}'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SILVER_DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "1e580b17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sgppipelinesa-silver/stage-01/1028-20100710-hne_signals.parquet',\n",
       " 'sgppipelinesa-silver/stage-01/1337ad-20170321-ajg_signals.parquet',\n",
       " 'sgppipelinesa-silver/stage-01/1337ad-20170321-tkg_signals.parquet',\n",
       " 'sgppipelinesa-silver/stage-01/1snoke-20120412-hge_signals.parquet',\n",
       " 'sgppipelinesa-silver/stage-01/23yipikaye-20100807-ujm_signals.parquet',\n",
       " 'sgppipelinesa-silver/stage-01/Aaron-20080318-kdl_signals.parquet',\n",
       " 'sgppipelinesa-silver/stage-01/Anniepoo-20140308-bft_signals.parquet',\n",
       " 'sgppipelinesa-silver/stage-01/Anniepoo-20140308-cqj_signals.parquet',\n",
       " 'sgppipelinesa-silver/stage-01/Anniepoo-20140308-fcp_signals.parquet',\n",
       " 'sgppipelinesa-silver/stage-01/Anniepoo-20140308-hns_signals.parquet',\n",
       " 'sgppipelinesa-silver/stage-01/Anniepoo-20140308-nky_signals.parquet',\n",
       " 'sgppipelinesa-silver/stage-01/Coren-20141121-pxp_signals.parquet']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cloud\n",
    "# create client with generated sas token\n",
    "datalake_service_client = DataLakeServiceClient(\n",
    "    account_url=f\"https://{storage_account_name}.dfs.core.windows.net\", \n",
    "    credential=credential\n",
    ")\n",
    "\n",
    "# retrieves file system client/container client \n",
    "# to retrieve datalake client\n",
    "silver_container_client = datalake_service_client.get_file_system_client(f\"{storage_account_name}-silver\")\n",
    "\n",
    "# we only get the directories in the first level of \n",
    "# the container, if it has a \"/\" then it means it is not\n",
    "# an immediate folder in the container. This only really\n",
    "# gets the subject folders \n",
    "signal_file_paths = [\n",
    "    os.path.join(\n",
    "        SILVER_FOLDER_NAME,\n",
    "        path.name\n",
    "    ).replace(\"\\\\\", \"/\") \n",
    "    for path in silver_container_client.get_paths(path=SUB_FOLDER_NAME) \n",
    "    if (not \"labels\" in path.name) and (\".parquet\" in path.name)\n",
    "]\n",
    "signal_file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9135ed29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_statistical_feats(subject_table, samples_per_win_size, samples_per_hop_size):\n",
    "    # connect to an in-memory database\n",
    "    conn = duckdb.connect()\n",
    "\n",
    "    # count = conn.sql(\"\"\"\n",
    "    #     SELECT COUNT(rowId) FROM subject_table\n",
    "    # \"\"\").fetchall()[-1][-1]\n",
    "\n",
    "    conn.sql(f\"\"\"\n",
    "        CREATE OR REPLACE TEMPORARY TABLE subject_features AS (\n",
    "            SELECT\n",
    "                -- signals, \n",
    "                subjectId, \n",
    "                -- rowId,\n",
    "                KURTOSIS(signals) OVER(PARTITION BY subjectId ORDER BY rowId ROWS BETWEEN CURRENT ROW AND {samples_per_win_size - 1} FOLLOWING) AS freq_kurt,\n",
    "                SKEWNESS(signals) OVER(PARTITION BY subjectId ORDER BY rowId ROWS BETWEEN CURRENT ROW AND {samples_per_win_size - 1} FOLLOWING) AS freq_skew,\n",
    "                ENTROPY(signals)OVER(PARTITION BY subjectId ORDER BY rowId ROWS BETWEEN CURRENT ROW AND {samples_per_win_size - 1} FOLLOWING) AS freq_entropy,\n",
    "                AVG(signals) OVER(PARTITION BY subjectId ORDER BY rowId ROWS BETWEEN CURRENT ROW AND {samples_per_win_size - 1} FOLLOWING) AS freq_mean,\n",
    "                MEDIAN(signals) OVER(PARTITION BY subjectId ORDER BY rowId ROWS BETWEEN CURRENT ROW AND {samples_per_win_size - 1} FOLLOWING) AS freq_median,\n",
    "                MODE(signals) OVER(PARTITION BY subjectId ORDER BY rowId ROWS BETWEEN CURRENT ROW AND {samples_per_win_size - 1} FOLLOWING) AS freq_mode,\n",
    "                MIN(signals) OVER(PARTITION BY subjectId ORDER BY rowId ROWS BETWEEN CURRENT ROW AND {samples_per_win_size - 1} FOLLOWING) AS freq_min,\n",
    "                MAX(signals) OVER(PARTITION BY subjectId ORDER BY rowId ROWS BETWEEN CURRENT ROW AND {samples_per_win_size - 1} FOLLOWING) AS freq_max,\n",
    "                VAR_SAMP(signals) OVER(PARTITION BY subjectId ORDER BY rowId ROWS BETWEEN CURRENT ROW AND {samples_per_win_size - 1} FOLLOWING) AS freq_var,\n",
    "                STDDEV_SAMP(signals) OVER(PARTITION BY subjectId ORDER BY rowId ROWS BETWEEN CURRENT ROW AND {samples_per_win_size - 1} FOLLOWING) AS freq_stddev,\n",
    "                QUANTILE_CONT(signals, 0.25) OVER(PARTITION BY subjectId ORDER BY rowId ROWS BETWEEN CURRENT ROW AND {samples_per_win_size - 1} FOLLOWING) AS freq_first_quart,\n",
    "                QUANTILE_CONT(signals, 0.75) OVER(PARTITION BY subjectId ORDER BY rowId ROWS BETWEEN CURRENT ROW AND {samples_per_win_size - 1} FOLLOWING) AS freq_third_quart\n",
    "            FROM subject_table\n",
    "            WHERE (rowId % {samples_per_hop_size}) = 0\n",
    "            ORDER BY rowId\n",
    "        )\n",
    "    \"\"\")\n",
    "\n",
    "    conn.sql(\"\"\"\n",
    "        CREATE OR REPLACE TEMPORARY TABLE subject_features AS (\n",
    "            SELECT \n",
    "                *,\n",
    "                (freq_max - freq_min) AS freq_range,\n",
    "                (freq_third_quart - freq_first_quart) AS freq_inter_quart_range\n",
    "            FROM subject_features\n",
    "        )\n",
    "    \"\"\")\n",
    "\n",
    "    subject_features = conn.sql(\"\"\"\n",
    "        SELECT * FROM subject_features\n",
    "    \"\"\").to_arrow_table()\n",
    "\n",
    "    return subject_features\n",
    "\n",
    "def compute_spectral_features(subject_features, x_signals, hertz, samples_per_win_size, samples_per_hop_size, n_frames):\n",
    "    zcr = librosa.feature.zero_crossing_rate(\n",
    "        y=x_signals, \n",
    "        frame_length=samples_per_win_size, \n",
    "        hop_length=samples_per_hop_size\n",
    "    )[:, :n_frames]\n",
    "    poly_feats = librosa.feature.poly_features(\n",
    "        y=x_signals, \n",
    "        sr=hertz, \n",
    "        n_fft=samples_per_win_size, \n",
    "        hop_length=samples_per_hop_size\n",
    "    )[:, :n_frames]\n",
    "\n",
    "    mel_spec = librosa.feature.melspectrogram(\n",
    "        y=x_signals, \n",
    "        sr=hertz, \n",
    "        n_fft=samples_per_win_size, \n",
    "        hop_length=samples_per_hop_size, \n",
    "        n_mels=90\n",
    "    )[:, :n_frames]\n",
    "    mel_spec_mean, \\\n",
    "    mel_spec_median, \\\n",
    "    mel_spec_mode, \\\n",
    "    mel_spec_mode_cnt, \\\n",
    "    mel_spec_min, \\\n",
    "    mel_spec_max, \\\n",
    "    mel_spec_range, \\\n",
    "    mel_spec_var, \\\n",
    "    mel_spec_std, \\\n",
    "    mel_spec_first_quart, \\\n",
    "    mel_spec_third_quart, \\\n",
    "    mel_spec_inter_quart_range, \\\n",
    "    mel_spec_entropy, \\\n",
    "    mel_spec_kurt, \\\n",
    "    mel_spec_skew = extract_spectogam_stats(mel_spec)\n",
    "\n",
    "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "    mel_spec_db_mean, \\\n",
    "    mel_spec_db_median, \\\n",
    "    mel_spec_db_mode, \\\n",
    "    mel_spec_db_mode_cnt, \\\n",
    "    mel_spec_db_min, \\\n",
    "    mel_spec_db_max, \\\n",
    "    mel_spec_db_range, \\\n",
    "    mel_spec_db_var, \\\n",
    "    mel_spec_db_std, \\\n",
    "    mel_spec_db_first_quart, \\\n",
    "    mel_spec_db_third_quart, \\\n",
    "    mel_spec_db_inter_quart_range, \\\n",
    "    mel_spec_db_entropy, \\\n",
    "    mel_spec_db_kurt, \\\n",
    "    mel_spec_db_skew = extract_spectogam_stats(mel_spec_db)\n",
    "\n",
    "    mfcc = librosa.feature.mfcc(\n",
    "        y=x_signals, \n",
    "        sr=hertz, \n",
    "        n_fft=samples_per_win_size, \n",
    "        hop_length=samples_per_hop_size, n_mfcc=90\n",
    "    )[:, :n_frames]\n",
    "    mfcc_mean, \\\n",
    "    mfcc_median, \\\n",
    "    mfcc_mode, \\\n",
    "    mfcc_mode_cnt, \\\n",
    "    mfcc_min, \\\n",
    "    mfcc_max, \\\n",
    "    mfcc_range, \\\n",
    "    mfcc_var, \\\n",
    "    mfcc_std, \\\n",
    "    mfcc_first_quart, \\\n",
    "    mfcc_third_quart, \\\n",
    "    mfcc_inter_quart_range, \\\n",
    "    mfcc_entropy, \\\n",
    "    mfcc_kurt, \\\n",
    "    mfcc_skew = extract_spectogam_stats(mfcc)\n",
    "    \n",
    "    spec_cont = librosa.feature.spectral_contrast(\n",
    "        y=x_signals, \n",
    "        sr=hertz, \n",
    "        n_fft=samples_per_win_size, \n",
    "        hop_length=samples_per_hop_size\n",
    "    )[:, :n_frames]\n",
    "    spec_cont_mean, \\\n",
    "    spec_cont_median, \\\n",
    "    spec_cont_mode, \\\n",
    "    spec_cont_mode_cnt, \\\n",
    "    spec_cont_min, \\\n",
    "    spec_cont_max, \\\n",
    "    spec_cont_range, \\\n",
    "    spec_cont_var, \\\n",
    "    spec_cont_std, \\\n",
    "    spec_cont_first_quart, \\\n",
    "    spec_cont_third_quart, \\\n",
    "    spec_cont_inter_quart_range, \\\n",
    "    spec_cont_entropy, \\\n",
    "    spec_cont_kurt, \\\n",
    "    spec_cont_skew = extract_spectogam_stats(spec_cont)\n",
    "\n",
    "    spec_cent = librosa.feature.spectral_centroid(\n",
    "        y=x_signals, \n",
    "        sr=hertz, \n",
    "        n_fft=samples_per_win_size, \n",
    "        hop_length=samples_per_hop_size\n",
    "    )[:, :n_frames]\n",
    "    spec_bw = librosa.feature.spectral_bandwidth(\n",
    "        y=x_signals, \n",
    "        sr=hertz, \n",
    "        n_fft=samples_per_win_size, \n",
    "        hop_length=samples_per_hop_size\n",
    "    )[:, :n_frames]\n",
    "    spec_flat = librosa.feature.spectral_flatness(\n",
    "        y=x_signals, \n",
    "        n_fft=samples_per_win_size, \n",
    "        hop_length=samples_per_hop_size\n",
    "    )[:, :n_frames]\n",
    "    spec_roll = librosa.feature.spectral_rolloff(\n",
    "        y=x_signals, \n",
    "        sr=hertz, \n",
    "        n_fft=samples_per_win_size, \n",
    "        hop_length=samples_per_hop_size\n",
    "    )[:, :n_frames]\n",
    "\n",
    "    # add the newly computed spectographic and chromagraphic\n",
    "    # features as columns\n",
    "    subject_features = subject_features.append_column(\"zcr\", [zcr.reshape(-1)])\n",
    "    subject_features = subject_features.append_column(\"poly_feat_1\", [poly_feats[0, :]])\n",
    "    subject_features = subject_features.append_column(\"poly_feat_2\", [poly_feats[1, :]])\n",
    "    subject_features = subject_features.append_column(\"spec_cent\", [spec_cent.reshape(-1)])\n",
    "    subject_features = subject_features.append_column(\"spec_bw\", [spec_bw.reshape(-1)])\n",
    "    subject_features = subject_features.append_column(\"spec_flat\", [spec_flat.reshape(-1)])\n",
    "    subject_features = subject_features.append_column(\"spec_roll\", [spec_roll.reshape(-1)])\n",
    "\n",
    "    subject_features = subject_features.append_column(\"mel_spec_mean\", [mel_spec_mean])\n",
    "    subject_features = subject_features.append_column(\"mel_spec_median\", [mel_spec_median])\n",
    "    subject_features = subject_features.append_column(\"mel_spec_mode\", [mel_spec_mode])\n",
    "    subject_features = subject_features.append_column(\"mel_spec_mode_cnt\", [mel_spec_mode_cnt])\n",
    "    subject_features = subject_features.append_column(\"mel_spec_min\", [mel_spec_min])\n",
    "    subject_features = subject_features.append_column(\"mel_spec_max\", [mel_spec_max])\n",
    "    subject_features = subject_features.append_column(\"mel_spec_range\", [mel_spec_range])\n",
    "    subject_features = subject_features.append_column(\"mel_spec_var\", [mel_spec_var])\n",
    "    subject_features = subject_features.append_column(\"mel_spec_std\", [mel_spec_std])\n",
    "    subject_features = subject_features.append_column(\"mel_spec_first_quart\", [mel_spec_first_quart])\n",
    "    subject_features = subject_features.append_column(\"mel_spec_third_quart\", [mel_spec_third_quart])\n",
    "    subject_features = subject_features.append_column(\"mel_spec_inter_quart_range\", [mel_spec_inter_quart_range])\n",
    "    subject_features = subject_features.append_column(\"mel_spec_entropy\", [mel_spec_entropy])\n",
    "    subject_features = subject_features.append_column(\"mel_spec_kurt\", [mel_spec_kurt])\n",
    "    subject_features = subject_features.append_column(\"mel_spec_skew\", [mel_spec_skew])\n",
    "\n",
    "    subject_features = subject_features.append_column(\"mel_spec_db_mean\", [mel_spec_db_mean])\n",
    "    subject_features = subject_features.append_column(\"mel_spec_db_median\", [mel_spec_db_median])\n",
    "    subject_features = subject_features.append_column(\"mel_spec_db_mode\", [mel_spec_db_mode])\n",
    "    subject_features = subject_features.append_column(\"mel_spec_db_mode_cnt\", [mel_spec_db_mode_cnt])\n",
    "    subject_features = subject_features.append_column(\"mel_spec_db_min\", [mel_spec_db_min])\n",
    "    subject_features = subject_features.append_column(\"mel_spec_db_max\", [mel_spec_db_max])\n",
    "    subject_features = subject_features.append_column(\"mel_spec_db_range\", [mel_spec_db_range])\n",
    "    subject_features = subject_features.append_column(\"mel_spec_db_var\", [mel_spec_db_var])\n",
    "    subject_features = subject_features.append_column(\"mel_spec_db_std\", [mel_spec_db_std])\n",
    "    subject_features = subject_features.append_column(\"mel_spec_db_first_quart\", [mel_spec_db_first_quart])\n",
    "    subject_features = subject_features.append_column(\"mel_spec_db_third_quart\", [mel_spec_db_third_quart])\n",
    "    subject_features = subject_features.append_column(\"mel_spec_db_inter_quart_range\", [mel_spec_db_inter_quart_range])\n",
    "    subject_features = subject_features.append_column(\"mel_spec_db_entropy\", [mel_spec_db_entropy])\n",
    "    subject_features = subject_features.append_column(\"mel_spec_db_kurt\", [mel_spec_db_kurt])\n",
    "    subject_features = subject_features.append_column(\"mel_spec_db_skew\", [mel_spec_db_skew])\n",
    "\n",
    "    subject_features = subject_features.append_column(\"mfcc_mean\", [mfcc_mean])\n",
    "    subject_features = subject_features.append_column(\"mfcc_median\", [mfcc_median])\n",
    "    subject_features = subject_features.append_column(\"mfcc_mode\", [mfcc_mode])\n",
    "    subject_features = subject_features.append_column(\"mfcc_mode_cnt\", [mfcc_mode_cnt])\n",
    "    subject_features = subject_features.append_column(\"mfcc_min\", [mfcc_min])\n",
    "    subject_features = subject_features.append_column(\"mfcc_max\", [mfcc_max])\n",
    "    subject_features = subject_features.append_column(\"mfcc_range\", [mfcc_range])\n",
    "    subject_features = subject_features.append_column(\"mfcc_var\", [mfcc_var])\n",
    "    subject_features = subject_features.append_column(\"mfcc_std\", [mfcc_std])\n",
    "    subject_features = subject_features.append_column(\"mfcc_first_quart\", [mfcc_first_quart])\n",
    "    subject_features = subject_features.append_column(\"mfcc_third_quart\", [mfcc_third_quart])\n",
    "    subject_features = subject_features.append_column(\"mfcc_inter_quart_range\", [mfcc_inter_quart_range])\n",
    "    subject_features = subject_features.append_column(\"mfcc_entropy\", [mfcc_entropy])\n",
    "    subject_features = subject_features.append_column(\"mfcc_kurt\", [mfcc_kurt])\n",
    "    subject_features = subject_features.append_column(\"mfcc_skew\", [mfcc_skew])\n",
    "\n",
    "    subject_features = subject_features.append_column(\"spec_cont_mean\", [spec_cont_mean])\n",
    "    subject_features = subject_features.append_column(\"spec_cont_median\", [spec_cont_median])\n",
    "    subject_features = subject_features.append_column(\"spec_cont_mode\", [spec_cont_mode])\n",
    "    subject_features = subject_features.append_column(\"spec_cont_mode_cnt\", [spec_cont_mode_cnt])\n",
    "    subject_features = subject_features.append_column(\"spec_cont_min\", [spec_cont_min])\n",
    "    subject_features = subject_features.append_column(\"spec_cont_max\", [spec_cont_max])\n",
    "    subject_features = subject_features.append_column(\"spec_cont_range\", [spec_cont_range])\n",
    "    subject_features = subject_features.append_column(\"spec_cont_var\", [spec_cont_var])\n",
    "    subject_features = subject_features.append_column(\"spec_cont_std\", [spec_cont_std])\n",
    "    subject_features = subject_features.append_column(\"spec_cont_first_quart\", [spec_cont_first_quart])\n",
    "    subject_features = subject_features.append_column(\"spec_cont_third_quart\", [spec_cont_third_quart])\n",
    "    subject_features = subject_features.append_column(\"spec_cont_inter_quart_range\", [spec_cont_inter_quart_range])\n",
    "    subject_features = subject_features.append_column(\"spec_cont_entropy\", [spec_cont_entropy])\n",
    "    subject_features = subject_features.append_column(\"spec_cont_kurt\", [spec_cont_kurt])\n",
    "    subject_features = subject_features.append_column(\"spec_cont_skew\", [spec_cont_skew])\n",
    "\n",
    "    return subject_features\n",
    "\n",
    "\n",
    "def test(signal_file_paths, \n",
    "    data_dir, \n",
    "    hertz: int=16000, \n",
    "    window_time: int=3, \n",
    "    hop_time: int=1, \n",
    "    storage_account_name: str=None, \n",
    "    credential: str=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    concurrently extracts the features of each signal\n",
    "    the first half of feature extraction involves using\n",
    "    sql for computing statistical features of the subjects\n",
    "    signals\n",
    "\n",
    "    the second half involves using librosa for computing\n",
    "    for instance spectral features of the sujects signals\n",
    "    as there is not supported function to compute audio\n",
    "    specific signal features like spectograms, chromagrams,\n",
    "    tempogram, etc.\n",
    "    \"\"\"\n",
    "    # make directory where subject features wil lbe saved\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "    \n",
    "    # we calculate the window size of each segment or the\n",
    "    # amount of samples it has to have based on the frequency\n",
    "    samples_per_win_size = int(window_time * hertz)\n",
    "    samples_per_hop_size = int(hop_time * hertz)\n",
    "\n",
    "    if storage_account_name and credential:\n",
    "        handler = pa_adl.AccountHandler.from_account_name(storage_account_name, credential=credential)\n",
    "        fs = pa.fs.PyFileSystem(handler)\n",
    "\n",
    "    def helper(signal_file_path):\n",
    "        try:\n",
    "            # extract subject name from file path\n",
    "            subject_id = signal_file_path.split(\"/\")[-1]\n",
    "            subject_id = subject_id.replace(\"_signals.parquet\", \"\")\n",
    "\n",
    "            # read subjects table and it ssignals\n",
    "            if storage_account_name and credential:\n",
    "                # cloud\n",
    "                subject_table = pq.read_table(signal_file_path, filesystem=fs)\n",
    "            else:\n",
    "                # local\n",
    "                subject_table = pq.read_table(signal_file_path)\n",
    "                \n",
    "            x_signals = subject_table[\"signals\"].to_numpy()\n",
    "\n",
    "            # calculate statistical features\n",
    "            subject_features = compute_statistical_feats(\n",
    "                subject_table, \n",
    "                samples_per_win_size, \n",
    "                samples_per_hop_size\n",
    "            )\n",
    "\n",
    "            # get the number of frames used using a window of 48000\n",
    "            # and hop length of 16000\n",
    "            n_frames = subject_features.shape[0]\n",
    "\n",
    "            # compute spectographic and chromagraphic features\n",
    "            subject_features = compute_spectral_features(\n",
    "                subject_features, \n",
    "                x_signals, \n",
    "                hertz, \n",
    "                samples_per_win_size, \n",
    "                samples_per_hop_size, \n",
    "                n_frames\n",
    "            )\n",
    "            \n",
    "            save_path = os.path.join(data_dir, f\"{subject_id}_signals.parquet\").replace(\"\\\\\", \"/\")\n",
    "            if storage_account_name and credential:\n",
    "                pq.write_table(subject_features, save_path,filesystem=fs)\n",
    "            else:\n",
    "                # write table to a 2nd sub stage in silver staging layer \n",
    "                pq.write_table(subject_features, save_path)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"error {e} occured on subject id: {subject_id}\")\n",
    "            \n",
    "            # return the last subjects features\n",
    "            return subject_id, e\n",
    "\n",
    "    # concurrently calculate statistical features and spectral\n",
    "    # features of each subject using DuckDB SQL and librosa\n",
    "    with ThreadPoolExecutor(max_workers=5) as exe:\n",
    "        subjects_features_list = list(exe.map(helper, signal_file_paths))\n",
    "\n",
    "    return subjects_features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "1c9fd6e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sgppipelinesa-silver/stage-02'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # local\n",
    "# SAVE_DIR = SILVER_DATA_DIR.format(\n",
    "#     DATA_DIR=DATA_DIR,\n",
    "#     SILVER_FOLDER_NAME=SILVER_FOLDER_NAME,\n",
    "#     SUB_FOLDER_NAME=\"stage-02\"\n",
    "# )\n",
    "# SAVE_DIR\n",
    "\n",
    "# cloud\n",
    "SAVE_DIR = SILVER_DATA_DIR.format(\n",
    "    FOLDER_NAME=SILVER_FOLDER_NAME,\n",
    "    SUB_FOLDER_NAME=\"stage-02\"\n",
    ")\n",
    "SAVE_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "dd31cabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects_features = test(signal_file_paths, SAVE_DIR, storage_account_name=storage_account_name, credential=credential)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tech-interview",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
