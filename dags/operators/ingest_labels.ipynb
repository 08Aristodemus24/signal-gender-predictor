{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import duckdb\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrowfs_adlgen2 as pa_adl\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "from azure.identity import DefaultAzureCredential, ClientSecretCredential\n",
    "from azure.storage.filedatalake import DataLakeServiceClient\n",
    "from azure.keyvault.secrets import SecretClient\n",
    "from azure.core.exceptions import ResourceNotFoundError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA_DIR = \"../include/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # local\n",
    "# BRONZE_FOLDER_NAME = \"bronze\"\n",
    "# BRONZE_DATA_DIR = os.path.join(\"{DATA_DIR}\", \"{FOLDER_NAME}\").replace(\"\\\\\", \"/\")\n",
    "# BRONZE_DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # local\n",
    "# file_infos = [\n",
    "#     os.path.join(BRONZE_DATA_DIR.format(DATA_DIR=DATA_DIR, FOLDER_NAME=BRONZE_FOLDER_NAME), file_info).replace(\"\\\\\", \"/\") \n",
    "#     for file_info in \n",
    "#     os.listdir(BRONZE_DATA_DIR.format(DATA_DIR=DATA_DIR, FOLDER_NAME=BRONZE_FOLDER_NAME))\n",
    "# ]\n",
    "# file_infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_paths = [\n",
    "#     os.path.join(file_info, \"etc\", \"README\").replace(\"\\\\\", \"/\") \n",
    "#     for file_info in file_infos \n",
    "#     if os.path.exists(os.path.join(file_info, \"etc\", \"README\").replace(\"\\\\\", \"/\"))\n",
    "# ]\n",
    "# label_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cloud (which will includde connecting to azure data lake storage via duck db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Retrieve credentials from environment variables\n",
    "# # this is strictly used only in development\n",
    "# # load env variables\n",
    "# env_dir = Path('../../').resolve()\n",
    "# load_dotenv(os.path.join(env_dir, '.env'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_account_name = os.environ.get(\"STORAGE_ACCOUNT_NAME\")\n",
    "credential = os.environ.get(\"STORAGE_ACCOUNT_KEY\")\n",
    "conn_str = os.environ.get(\"STORAGE_ACCOUNT_CONN_STR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cloud\n",
    "URL = \"abfss://{STORAGE_ACCOUNT_NAME}.dfs.core.windows.net/{FOLDER_NAME}\"\n",
    "BRONZE_FOLDER_NAME = f\"{storage_account_name}-bronze\"\n",
    "BRONZE_DATA_DIR = URL.format(\n",
    "    STORAGE_ACCOUNT_NAME=storage_account_name,\n",
    "    FOLDER_NAME=BRONZE_FOLDER_NAME\n",
    ")\n",
    "BRONZE_DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cloud\n",
    "# create client with generated sas token\n",
    "datalake_service_client = DataLakeServiceClient(\n",
    "    account_url=f\"https://{storage_account_name}.dfs.core.windows.net\", \n",
    "    credential=credential\n",
    ")\n",
    "\n",
    "# retrieves file system client/container client \n",
    "# to retrieve datalake client\n",
    "bronze_container_client = datalake_service_client.get_file_system_client(f\"{storage_account_name}-bronze\")\n",
    "\n",
    "# we only get the directories in the first level of \n",
    "# the container, if it has a \"/\" then it means it is not\n",
    "# an immediate folder in the container. This only really\n",
    "# gets the subject folders \n",
    "subject_folders = [path.name for path in bronze_container_client.get_paths() if not \"/\" in path.name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_infos = [os.path.join(BRONZE_DATA_DIR, subject_folder).replace(\"\\\\\", \"/\") for subject_folder in subject_folders]\n",
    "file_infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need some way to ensure the path also exists\n",
    "label_paths = [\n",
    "    os.path.join(file_info, \"etc\", \"README\").replace(\"\\\\\", \"/\") \n",
    "    for i, file_info in enumerate(file_infos) \n",
    "    if bronze_container_client\n",
    "    .get_file_client(file_path=f\"{subject_folders[i]}/etc/README\")\n",
    "    .exists()\n",
    "]\n",
    "label_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = duckdb.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for cloud only\n",
    "# installing dependencies and creating secrets object\n",
    "conn.sql(f\"\"\"INSTALL azure\"\"\")\n",
    "conn.sql(f\"\"\"LOAD azure\"\"\")\n",
    "conn.sql(f\"\"\"\n",
    "    CREATE OR REPLACE SECRET az_sgp (\n",
    "        TYPE azure,\n",
    "        CONNECTION_STRING '{conn_str}'\n",
    "    );\n",
    "\"\"\")\n",
    "# the is required if this notebook is run in linux environment\n",
    "# like airflow container\n",
    "conn.sql(\"SET azure_transport_option_type = 'curl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.sql(f\"\"\"\n",
    "    CREATE OR REPLACE TEMPORARY TABLE split_raw_labels AS (\n",
    "        WITH raw_labels AS (\n",
    "            SELECT \n",
    "                filename, \n",
    "                content \n",
    "            FROM read_text({label_paths})\n",
    "        )\n",
    "\n",
    "        SELECT \n",
    "            filename, \n",
    "            REGEXP_SPLIT_TO_TABLE(content, '\\n\\n*') AS value \n",
    "        FROM raw_labels\n",
    "    )\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.sql(\"\"\"\n",
    "    SELECT *  FROM split_raw_labels \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# clean value column containing the label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.sql(\"\"\"\n",
    "    CREATE OR REPLACE TEMPORARY TABLE subjects_labels AS (\n",
    "        -- remove the rows with no gender meta data of the subject\n",
    "        WITH subjects_labels_1 AS (\n",
    "            SELECT * \n",
    "            FROM split_raw_labels\n",
    "            WHERE 'gender' IN LCASE(value)\n",
    "        ),\n",
    "\n",
    "        subjects_labels_2 AS (\n",
    "            SELECT\n",
    "                -- remove punctuations in the meta data of the subject\n",
    "                -- containing its gender\n",
    "                REGEXP_REPLACE(LCASE(value), '[:;\\[\\]\\t\\n\\s]+', '') AS value,\n",
    "                filename\n",
    "            FROM subjects_labels_1\n",
    "        ),\n",
    "\n",
    "        subjects_labels_3 AS (\n",
    "            SELECT\n",
    "                -- remove 'gender' in meta data of the subject containing\n",
    "                -- its gender\n",
    "                REGEXP_REPLACE(value, 'gender', '') AS value,\n",
    "                filename\n",
    "            FROM subjects_labels_2\n",
    "        ),\n",
    "            \n",
    "        subjects_labels_4 AS (\n",
    "            SELECT\n",
    "                CASE\n",
    "                    WHEN STARTS_WITH(value, 'ma') OR STARTS_WITH(value, 'm√§') THEN 'male'\n",
    "                    WHEN STARTS_WITH(value, 'fem') OR STARTS_WITH(value, 'wei') THEN 'female'\n",
    "            \n",
    "                    -- whenever unknown gender is encountered just generate random\n",
    "                    -- gender of either male or female with prob of 50%\n",
    "                    ELSE \n",
    "                        (CASE \n",
    "                            WHEN RANDOM() < 0.5 THEN 'male'\n",
    "                            ELSE 'female'\n",
    "                        END)\n",
    "                END AS value,\n",
    "                filename\n",
    "            FROM subjects_labels_3\n",
    "        )\n",
    "            \n",
    "        SELECT * FROM subjects_labels_4\n",
    "    )\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.sql(\"\"\"\n",
    "    SELECT * FROM subjects_labels\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# clean filename column and turn into subjectid column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.sql(\"\"\"\n",
    "    CREATE OR REPLACE TEMPORARY TABLE subjects_labels AS (\n",
    "        SELECT\n",
    "            -- splits the file path on the '/' character which\n",
    "            -- results in a list that we can use to extract the\n",
    "            -- third to the last value in this list\n",
    "            LIST_EXTRACT(STRING_SPLIT(filename, '/'), -3) AS subjectId,\n",
    "            value\n",
    "        FROM subjects_labels\n",
    "    )\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.sql(\"\"\"\n",
    "    SELECT * FROM subjects_labels\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# once the `value`'s and `subjectId`'s is cleaned we can now split the dataset uniformly. We need to split first on the male and female subjects so that we can evenly split these male and female sets into train, val, and test sets, and then later rejoin the train, val, and test sets of the male and female sets  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.sql(\"\"\"\n",
    "    CREATE OR REPLACE TEMPORARY TABLE male_subjects_labels AS (\n",
    "        SELECT \n",
    "            *, \n",
    "            ROW_NUMBER() OVER(ORDER BY subjectId) AS split_row_id \n",
    "        FROM subjects_labels\n",
    "        WHERE value = 'male'\n",
    "    );\n",
    "    \n",
    "    CREATE OR REPLACE TEMPORARY TABLE female_subjects_labels AS (\n",
    "        SELECT \n",
    "            *, \n",
    "            ROW_NUMBER() OVER(ORDER BY subjectId) AS split_row_id \n",
    "        FROM subjects_labels\n",
    "        WHERE value = 'female'\n",
    "    );    \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create a 70, 15, 15 ratio for the training, validation, and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates 70, 15, 15 ratio for male labels\n",
    "conn.sql(\"\"\"\n",
    "    CREATE OR REPLACE TEMPORARY TABLE male_subjects_labels_split AS (\n",
    "        -- split the male subjects labels into train and test \n",
    "        WITH male_subjects_labels_train__ AS (\n",
    "            SELECT \n",
    "                *,\n",
    "                CASE\n",
    "                    WHEN split_row_id <= (SELECT COUNT(*) * 0.7 FROM male_subjects_labels) THEN 'train'\n",
    "                    ELSE 'test'\n",
    "                END AS split\n",
    "            FROM male_subjects_labels\n",
    "        ),\n",
    "        \n",
    "        -- recalculate the test splits split row id so it \n",
    "        -- starts from 1 to n again \n",
    "        temp AS (\n",
    "            SELECT \n",
    "                * EXCLUDE(split_row_id), \n",
    "                ROW_NUMBER() OVER(ORDER BY subjectId) AS split_row_id\n",
    "            FROM male_subjects_labels_train__\n",
    "            WHERE split = 'test'\n",
    "        ),\n",
    "        \n",
    "        -- split again the previous test set into now the real\n",
    "        -- validation and testing sets\n",
    "        male_subjects_labels_val_test AS (\n",
    "            SELECT\n",
    "                * EXCLUDE(split),\n",
    "                CASE\n",
    "                    WHEN split_row_id <= (SELECT COUNT(*) * 0.5 FROM temp) THEN 'val'\n",
    "                    ELSE 'test'\n",
    "                END AS split\n",
    "            FROM temp\n",
    "        )\n",
    "        \n",
    "        -- unionize the male subjects labels with validation\n",
    "        -- and testing splits and the previous male subjects\n",
    "        -- labels with the train splits \n",
    "        SELECT * FROM male_subjects_labels_val_test\n",
    "        UNION BY NAME\n",
    "        SELECT * FROM male_subjects_labels_train__\n",
    "        WHERE split = 'train'\n",
    "    )\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.sql(\"\"\"\n",
    "    SELECT * FROM male_subjects_labels_split\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates 70, 15, 15 ratio for female labels\n",
    "conn.sql(\"\"\"\n",
    "    CREATE OR REPLACE TEMPORARY TABLE female_subjects_labels_split AS (\n",
    "        -- split the female subjects labels into train and test \n",
    "        WITH female_subjects_labels_train__ AS (\n",
    "            SELECT \n",
    "                *,\n",
    "                CASE\n",
    "                    WHEN split_row_id <= (SELECT COUNT(*) * 0.7 FROM female_subjects_labels) THEN 'train'\n",
    "                    ELSE 'test'\n",
    "                END AS split\n",
    "            FROM female_subjects_labels\n",
    "        ),\n",
    "        \n",
    "        -- recalculate the test splits split row id so it \n",
    "        -- starts from 1 to n again \n",
    "        temp AS (\n",
    "            SELECT \n",
    "                * EXCLUDE(split_row_id), \n",
    "                ROW_NUMBER() OVER(ORDER BY subjectId) AS split_row_id\n",
    "            FROM female_subjects_labels_train__\n",
    "            WHERE split = 'test'\n",
    "        ),\n",
    "        \n",
    "        -- split again the previous test set into now the real\n",
    "        -- validation and testing sets\n",
    "        female_subjects_labels_val_test AS (\n",
    "            SELECT\n",
    "                * EXCLUDE(split),\n",
    "                CASE\n",
    "                    WHEN split_row_id <= (SELECT COUNT(*) * 0.5 FROM temp) THEN 'val'\n",
    "                    ELSE 'test'\n",
    "                END AS split\n",
    "            FROM temp\n",
    "        )\n",
    "        \n",
    "        -- unionize the female subjects labels with validation\n",
    "        -- and testing splits and the previous female subjects\n",
    "        -- labels with the train splits \n",
    "        SELECT * FROM female_subjects_labels_val_test\n",
    "        UNION BY NAME\n",
    "        SELECT * FROM female_subjects_labels_train__\n",
    "        WHERE split = 'train'\n",
    "    )\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.sql(\"\"\"\n",
    "    SELECT * FROM female_subjects_labels_split\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rejoin/unionize the male and female subjects labels based on their split as well as recreate new `rowId`'s for each split and create a partition column for each split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_partitions = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.sql(f\"\"\"\n",
    "    CREATE OR REPLACE TEMPORARY TABLE train_labels AS (\n",
    "        WITH subjects_labels_split AS (\n",
    "            SELECT subjectId, value, split\n",
    "            FROM female_subjects_labels_split\n",
    "            WHERE split = 'train'\n",
    "            \n",
    "            UNION BY NAME\n",
    "            \n",
    "            SELECT subjectId, value, split\n",
    "            FROM male_subjects_labels_split\n",
    "            WHERE split = 'train'\n",
    "        ),\n",
    "         \n",
    "        -- create new rowIds for the split\n",
    "        train_labels AS (\n",
    "            SELECT\n",
    "                *,\n",
    "                ROW_NUMBER() OVER(ORDER BY subjectId) - 1 AS rowId\n",
    "            FROM subjects_labels_split\n",
    "        )\n",
    "         \n",
    "        -- creawte partition column\n",
    "        SELECT\n",
    "            *,\n",
    "            rowId % {n_partitions} AS partition\n",
    "        FROM train_labels\n",
    "    );\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_table = conn.sql(\"\"\"\n",
    "    SELECT * FROM train_labels\n",
    "\"\"\").to_arrow_table()\n",
    "train_labels_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.sql(f\"\"\"\n",
    "    CREATE OR REPLACE TEMPORARY TABLE val_labels AS (\n",
    "        WITH subjects_labels_split AS (\n",
    "            SELECT subjectId, value, split\n",
    "            FROM female_subjects_labels_split\n",
    "            WHERE split = 'val'\n",
    "            \n",
    "            UNION BY NAME\n",
    "            \n",
    "            SELECT subjectId, value, split\n",
    "            FROM male_subjects_labels_split\n",
    "            WHERE split = 'val'\n",
    "        ),\n",
    "         \n",
    "        -- create new rowIds for the split\n",
    "        val_labels AS (\n",
    "            SELECT\n",
    "                *,\n",
    "                ROW_NUMBER() OVER(ORDER BY subjectId) - 1 AS rowId\n",
    "            FROM subjects_labels_split\n",
    "        )\n",
    "         \n",
    "        -- creawte partition column\n",
    "        SELECT\n",
    "            *,\n",
    "            rowId % {n_partitions} AS partition\n",
    "        FROM val_labels\n",
    "    );\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_labels_table = conn.sql(\"\"\"         \n",
    "    SELECT * FROM val_labels\n",
    "\"\"\").to_arrow_table()\n",
    "val_labels_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.sql(f\"\"\"\n",
    "    CREATE OR REPLACE TEMPORARY TABLE test_labels AS (\n",
    "        WITH subjects_labels_split AS (\n",
    "            SELECT subjectId, value, split\n",
    "            FROM female_subjects_labels_split\n",
    "            WHERE split = 'test'\n",
    "            \n",
    "            UNION BY NAME\n",
    "            \n",
    "            SELECT subjectId, value, split\n",
    "            FROM male_subjects_labels_split\n",
    "            WHERE split = 'test'\n",
    "        ),\n",
    "         \n",
    "        -- create new rowIds for the split\n",
    "        test_labels AS (\n",
    "            SELECT\n",
    "                *,\n",
    "                ROW_NUMBER() OVER(ORDER BY subjectId) - 1 AS rowId\n",
    "            FROM subjects_labels_split\n",
    "        )\n",
    "         \n",
    "        -- creawte partition column\n",
    "        SELECT\n",
    "            *,\n",
    "            rowId % {n_partitions} AS partition\n",
    "        FROM test_labels\n",
    "    );\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels_table = conn.sql(\"\"\"\n",
    "    SELECT * FROM test_labels\n",
    "\"\"\").to_arrow_table()\n",
    "test_labels_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save the data to azure data lake or locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # local\n",
    "# SILVER_FOLDER_NAME = \"silver\"\n",
    "# SUB_FOLDER_NAME = \"stage-01\"\n",
    "# SILVER_DATA_DIR = os.path.join(\"{DATA_DIR}\", \"{FOLDER_NAME}\", \"{SUB_FOLDER_NAME}\").replace(\"\\\\\", \"/\")\n",
    "# SILVER_DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE_DIR = SILVER_DATA_DIR.format(\n",
    "#     DATA_DIR=DATA_DIR,\n",
    "#     FOLDER_NAME=SILVER_FOLDER_NAME,\n",
    "#     SUB_FOLDER_NAME=SUB_FOLDER_NAME\n",
    "# )\n",
    "# os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "# SAVE_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cloud\n",
    "# URL = \"abfss://{FOLDER_NAME}@sgppipelinesa.dfs.core.windows.net\"\n",
    "URL = \"{FOLDER_NAME}\"\n",
    "SILVER_FOLDER_NAME = \"sgppipelinesa-silver\"\n",
    "SUB_FOLDER_NAME = \"stage-01\"\n",
    "SILVER_DATA_DIR = os.path.join(URL, \"{SUB_FOLDER_NAME}\").replace(\"\\\\\", \"/\")\n",
    "SILVER_DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DIR = SILVER_DATA_DIR.format(\n",
    "    FOLDER_NAME=SILVER_FOLDER_NAME,\n",
    "    SUB_FOLDER_NAME=SUB_FOLDER_NAME\n",
    ")\n",
    "SAVE_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unfortunately writing to azure using duckdb is not possible yet so workaround is to use pyarrow table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conn.sql(f\"\"\"\n",
    "#     COPY (SELECT * FROM train_labels) TO '{SAVE_DIR}/train_labels.parquet' (FORMAT parquet, PARTITION_BY partition, OVERWRITE)\n",
    "# \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handler = pa_adl.AccountHandler.from_account_name(storage_account_name, credential=credential)\n",
    "fs = pa.fs.PyFileSystem(handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pq.write_table(train_labels_table, f\"{SAVE_DIR}/train_labels.parquet\", filesystem=fs)\n",
    "pq.write_table(val_labels_table, f\"{SAVE_DIR}/val_labels.parquet\", filesystem=fs)\n",
    "pq.write_table(test_labels_table, f\"{SAVE_DIR}/test_labels.parquet\", filesystem=fs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tech-interview",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
